"<<pipeline-name>>-reader":
  source:
    documentdb: "<<$.<<pipeline-name>>.source.documentdb>>"
  routes:
    - initial_load: 'getMetadata("ingestion_type") == "EXPORT"'
    - stream_load: 'getMetadata("ingestion_type") == "STREAM"'
  sink:
    - s3:
        routes:
          - initial_load
        aws:
          region:  "<<$.<<pipeline-name>>.source.documentdb.s3_region>>"
          sts_role_arn: "<<$.<<pipeline-name>>.source.documentdb.aws.sts_role_arn>>"
          sts_external_id: "<<$.<<pipeline-name>>.source.documentdb.aws.sts_external_id>>"
          sts_header_overrides: "<<$.<<pipeline-name>>.source.documentdb.aws.sts_header_overrides>>"
        bucket: "<<$.<<pipeline-name>>.source.documentdb.s3_bucket>>"
        threshold:
          event_collect_timeout: "120s"
          maximum_size: "2mb"
        aggregate_threshold:
          maximum_size: "256kb"
          flush_capacity_ratio: 0
        object_key:
          path_prefix: "${getMetadata(\"s3_partition_key\")}"
        codec:
          json:
    - s3:
        routes:
          - stream_load
        aws:
          region:  "<<$.<<pipeline-name>>.source.documentdb.s3_region>>"
          sts_role_arn: "<<$.<<pipeline-name>>.source.documentdb.aws.sts_role_arn>>"
        bucket: "<<$.<<pipeline-name>>.source.documentdb.s3_bucket>>"
        threshold:
          event_collect_timeout: "30s"
          maximum_size: "1mb"
        aggregate_threshold:
          maximum_size: "128mb"
          flush_capacity_ratio: 0
        object_key:
          path_prefix: "${getMetadata(\"s3_partition_key\")}"
        codec:
          json:

"<<pipeline-name>>-writer":
    source:
      s3:
        codec:
          json:
        compression: "none"
        aws:
          region:  "<<$.<<pipeline-name>>.source.documentdb.s3_region>>"
          sts_role_arn: "<<$.<<pipeline-name>>.source.documentdb.aws.sts_role_arn>>"
          sts_external_id: "<<$.<<pipeline-name>>.source.documentdb.aws.sts_external_id>>"
          sts_header_overrides: "<<$.<<pipeline-name>>.source.documentdb.aws.sts_header_overrides>>"
        acknowledgments: true
        delete_s3_objects_on_read: true
        scan:
          buckets:
            - bucket:
                name: "<<$.<<pipeline-name>>.source.documentdb.s3_bucket>>"
                filter:
                  depth: "<<FUNCTION_NAME:calculateDepth,PARAMETER:$.<<pipeline-name>>.source.documentdb.s3_prefix>>"
        scheduling:
          interval: "1s"
    processor: "<<$.<<pipeline-name>>.processor>>"
    sink: "<<$.<<pipeline-name>>.sink>>"
